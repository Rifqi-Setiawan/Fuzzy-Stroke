{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd53719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "# Mengabaikan peringatan yang mungkin muncul untuk tampilan yang lebih bersih\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class StrokeDataPreprocessor:\n",
    "    \"\"\"\n",
    "    Sebuah kelas untuk melakukan semua langkah prapemrosesan pada dataset stroke\n",
    "    untuk persiapan pembuatan Sistem Fuzzy.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Inisialisasi imputer dan encoder\"\"\"\n",
    "        self.imputer_bmi = SimpleImputer(strategy='median')\n",
    "        self.label_encoders = {}\n",
    "        self.processed_data = None\n",
    "\n",
    "    def _load_data(self, file_path):\n",
    "        \"\"\"Memuat data dari file CSV.\"\"\"\n",
    "        print(\"1. Memuat dataset...\")\n",
    "        try:\n",
    "            return pd.read_csv(file_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File tidak ditemukan di {file_path}\")\n",
    "            return None\n",
    "\n",
    "    def _handle_anomalies_and_irrelevant_columns(self, df):\n",
    "        \"\"\"Menghapus kolom tidak relevan dan anomali data.\"\"\"\n",
    "        print(\"2. Menghapus kolom 'id' dan baris anomali (gender='Other')...\")\n",
    "        \n",
    "        # Hapus kolom 'id' karena tidak relevan\n",
    "        if 'id' in df.columns:\n",
    "            df = df.drop('id', axis=1)\n",
    "        \n",
    "        # Hapus baris dengan gender 'Other' karena hanya ada 1 data\n",
    "        if 'gender' in df.columns:\n",
    "            df = df[df['gender'] != 'Other']\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def _handle_missing_values(self, df):\n",
    "        \"\"\"Menangani nilai yang hilang pada kolom 'bmi'.\"\"\"\n",
    "        print(\"3. Menangani missing values pada kolom 'bmi' dengan median...\")\n",
    "        df['bmi'] = self.imputer_bmi.fit_transform(df[['bmi']])\n",
    "        return df\n",
    "\n",
    "    def _encode_categorical_features(self, df):\n",
    "        \"\"\"Melakukan label encoding pada fitur kategorikal.\"\"\"\n",
    "        print(\"4. Melakukan encoding pada fitur-fitur kategorikal...\")\n",
    "        categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            self.label_encoders[col] = le\n",
    "        return df\n",
    "\n",
    "    def process(self, file_path):\n",
    "        \"\"\"\n",
    "        Menjalankan seluruh pipeline prapemrosesan data.\n",
    "        \"\"\"\n",
    "        # Langkah 1: Muat data\n",
    "        data = self._load_data(file_path)\n",
    "        if data is None:\n",
    "            return None\n",
    "        \n",
    "        # Langkah 2: Handle kolom yang tidak relevan\n",
    "        data = self._handle_anomalies_and_irrelevant_columns(data)\n",
    "        \n",
    "        # Menghapus duplikasi data\n",
    "        data = data.drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        # Langkah 3: Handle missing values\n",
    "        data = self._handle_missing_values(data)\n",
    "        \n",
    "        # Langkah 4: Encoding fitur kategorikal\n",
    "        data = self._encode_categorical_features(data)\n",
    "        print(\"\\n=== Proses Prapemrosesan Selesai! ===\")\n",
    "        self.processed_data = data\n",
    "        return data\n",
    "\n",
    "    def explore_processed_data(self):\n",
    "        \"\"\"Menampilkan informasi ringkas mengenai data yang sudah diproses.\"\"\"\n",
    "        if self.processed_data is not None:\n",
    "            print(\"\\n=== INFORMASI DATASET SETELAH DIPROSES ===\")\n",
    "            print(f\"Bentuk Data: {self.processed_data.shape}\")\n",
    "            print(\"\\nInfo Tipe Data:\")\n",
    "            self.processed_data.info()\n",
    "            print(\"\\nContoh 5 Baris Data Teratas:\")\n",
    "            print(self.processed_data.head())\n",
    "            print(\"\\nStatistik Deskriptif Fitur Numerik:\")\n",
    "            print(self.processed_data[['age', 'avg_glucose_level', 'bmi']].describe())\n",
    "        else:\n",
    "            print(\"Data belum diproses. Jalankan method process() terlebih dahulu.\")\n",
    "            \n",
    "    def save_processed_data(self, output_path):\n",
    "        \"\"\"Menyimpan data yang sudah bersih ke file CSV.\"\"\"\n",
    "        if self.processed_data is not None:\n",
    "            self.processed_data.to_csv(output_path, index=False)\n",
    "            print(f\"\\nData yang sudah diproses telah disimpan di: {output_path}\")\n",
    "        else:\n",
    "            print(\"Tidak ada data untuk disimpan. Jalankan method process() terlebih dahulu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ef8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StrokeDataPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ccbba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Memuat dataset...\n",
      "2. Menghapus kolom 'id' dan baris anomali (gender='Other')...\n",
      "3. Menangani missing values pada kolom 'bmi' dengan median...\n",
      "4. Melakukan encoding pada fitur-fitur kategorikal...\n",
      "\n",
      "=== Proses Prapemrosesan Selesai! ===\n"
     ]
    }
   ],
   "source": [
    "# 2. Jalankan seluruh proses\n",
    "clean_df = preprocessor.process('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a502c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INFORMASI DATASET SETELAH DIPROSES ===\n",
      "Bentuk Data: (5109, 11)\n",
      "\n",
      "Info Tipe Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5109 entries, 0 to 5108\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5109 non-null   int32  \n",
      " 1   age                5109 non-null   float64\n",
      " 2   hypertension       5109 non-null   int64  \n",
      " 3   heart_disease      5109 non-null   int64  \n",
      " 4   ever_married       5109 non-null   int32  \n",
      " 5   work_type          5109 non-null   int32  \n",
      " 6   Residence_type     5109 non-null   int32  \n",
      " 7   avg_glucose_level  5109 non-null   float64\n",
      " 8   bmi                5109 non-null   float64\n",
      " 9   smoking_status     5109 non-null   int32  \n",
      " 10  stroke             5109 non-null   int64  \n",
      "dtypes: float64(3), int32(5), int64(3)\n",
      "memory usage: 339.4 KB\n",
      "\n",
      "Contoh 5 Baris Data Teratas:\n",
      "   gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
      "0       1  67.0             0              1             1          2   \n",
      "1       0  61.0             0              0             1          3   \n",
      "2       1  80.0             0              1             1          2   \n",
      "3       0  49.0             0              0             1          2   \n",
      "4       0  79.0             1              0             1          3   \n",
      "\n",
      "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
      "0               1             228.69  36.6               1       1  \n",
      "1               0             202.21  28.1               2       1  \n",
      "2               0             105.92  32.5               2       1  \n",
      "3               1             171.23  34.4               3       1  \n",
      "4               0             174.12  24.0               2       1  \n",
      "\n",
      "Statistik Deskriptif Fitur Numerik:\n",
      "               age  avg_glucose_level          bmi\n",
      "count  5109.000000        5109.000000  5109.000000\n",
      "mean     43.229986         106.140399    28.863300\n",
      "std      22.613575          45.285004     7.699785\n",
      "min       0.080000          55.120000    10.300000\n",
      "25%      25.000000          77.240000    23.800000\n",
      "50%      45.000000          91.880000    28.100000\n",
      "75%      61.000000         114.090000    32.800000\n",
      "max      82.000000         271.740000    97.600000\n",
      "\n",
      "Data yang sudah diproses telah disimpan di: stroke_preprocessed_for_fuzzy.csv\n"
     ]
    }
   ],
   "source": [
    "if clean_df is not None:\n",
    "    preprocessor.explore_processed_data()\n",
    "    \n",
    "    # 4. Simpan data bersih ke file baru untuk digunakan di tahap selanjutnya\n",
    "    preprocessor.save_processed_data('stroke_preprocessed_for_fuzzy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
